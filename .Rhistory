ggplot(productivity_df, aes(x=Training, y=ResolvedIssues, color=Training)) + geom_point()
ggplot(productivity_df, aes(x=Store, y=ResolvedIssues, color=Training))+geom_boxplot()
productivity_lmm0 <- lmer(ResolvedIssues ~ (1|Store), data=productivity_df)
productivity_lmm1 <- lmer(ResolvedIssues ~ Training + (1|Store), data=productivity_df)
anova(productivity_lmm0,productivity_lmm1)
ranova(productivity_lmm1)
qqnorm(resid(productivity_lmm1))
qqline(resid(productivity_lmm1), col=2)
plot(productivity_lmm1)
lilies_df <- read.csv("lilies.csv")
str(lilies_df)
ggplot(lilies_df, aes(x = HeightIncrease)) +
geom_dotplot()
ggplot(lilies_df, aes(x = LightIntensity)) +
geom_dotplot()
ggplot(lilies_df, aes(x = LightIntensity, y = HeightIncrease)) +
geom_point()
ggplot(lilies_df, aes(x = Genotype, y = LightIntensity)) +
geom_boxplot()
ggplot(lilies_df, aes(x = Genotype, y = HeightIncrease)) +
geom_boxplot()
lilies_df$Genotype <- as.factor(lilies_df$Genotype)
ggplot(lilies_df, aes(x = LightIntensity, y = HeightIncrease)) +
geom_point()
ggplot(lilies_df, aes(x=LightIntensity, y=HeightIncrease, color=Genotype)) + geom_point() +
facet_grid(~Genotype) +
scale_x_continuous(labels = scales::comma_format())
mlm.lilies_df <- lmer(HeightIncrease ~ LightIntensity + (1|Genotype), data = lilies_df)
mlm.lilies_df0 <- lmer(HeightIncrease ~ 1 + (1|Genotype), data = lilies_df)
anova(mlm.lilies_df0, mlm.lilies_df)
qqnorm(resid(mlm.lilies_df))
qqline(resid(mlm.lilies_df), col=2)
plot(mlm.lilies_df)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(Matrix)
library(lme4)
library(lmerTest)
productivity_df <- read.csv("productivity.csv")
str(productivity_df)
summary(productivity_df)
productivity_df$Training <- as.factor(productivity_df$Training)
productivity_df$Store <- as.factor(productivity_df$Store)
summary(productivity_df)
ggplot(productivity_df, aes(x=Training, y=ResolvedIssues, color=Training)) + geom_point()
ggplot(productivity_df, aes(x=Store, y=ResolvedIssues, color=Training))+geom_boxplot()
productivity_lmm0 <- lmer(ResolvedIssues ~ (1|Store), data=productivity_df)
productivity_lmm1 <- lmer(ResolvedIssues ~ Training + (1|Store), data=productivity_df)
anova(productivity_lmm0,productivity_lmm1)
ranova(productivity_lmm1)
qqnorm(resid(productivity_lmm1))
qqline(resid(productivity_lmm1), col=2)
plot(productivity_lmm1)
lilies_df <- read.csv("lilies.csv")
str(lilies_df)
ggplot(lilies_df, aes(x = HeightIncrease)) +
geom_dotplot()
ggplot(lilies_df, aes(x = LightIntensity)) +
geom_dotplot()
ggplot(lilies_df, aes(x = LightIntensity, y = HeightIncrease)) +
geom_point()
ggplot(lilies_df, aes(x = Genotype, y = LightIntensity)) +
geom_boxplot()
ggplot(lilies_df, aes(x = Genotype, y = HeightIncrease)) +
geom_boxplot()
lilies_df$Genotype <- as.factor(lilies_df$Genotype)
ggplot(lilies_df, aes(x = LightIntensity, y = HeightIncrease)) +
geom_point()
ggplot(lilies_df, aes(x=LightIntensity, y=HeightIncrease, color=Genotype)) + geom_point() +
facet_grid(~Genotype) +
scale_x_continuous(labels = scales::comma_format())
mlm.lilies_df <- lmer(HeightIncrease ~ LightIntensity + (1|Genotype), data = lilies_df)
mlm.lilies_df0 <- lmer(HeightIncrease ~ 1 + (1|Genotype), data = lilies_df)
anova(mlm.lilies_df0, mlm.lilies_df)
qqnorm(resid(mlm.lilies_df))
qqline(resid(mlm.lilies_df), col=2)
plot(mlm.lilies_df)
library(tidyverse)
library(lmerTest)
library(Matrix)
library(lme4)
marketing_df <- read.csv('marketing.csv')
str(marketing_df)
ggplot(aes(y=Engagement, x=Fashion, color=PostType), data=marketing_df) + geom_boxplot()
marketing_df$Engagement <- as.factor(marketing_df$Engagement)
ggplot(aes(y=Engagement, x=Fashion, color=PostType), data=marketing_df) + geom_boxplot()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lmerTest)
library(Matrix)
library(lme4)
str(marketing_df)
marketing_df$PostType <- as.factor(marketing_df$PostType)
marketing_df$Fashion <- as.factor(marketing_df$Fashion)
ggplot(aes(y=Engagement, x=Fashion, color=PostType), data=marketing_df) + geom_boxplot()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lmerTest)
library(Matrix)
library(lme4)
marketing_df <- read.csv('marketing.csv')
str(marketing_df)
marketing_df$PostType <- as.factor(marketing_df$PostType)
marketing_df$Fashion <- as.factor(marketing_df$Fashion)
ggplot(aes(y=Engagement, x=Fashion, color=PostType), data=marketing_df) + geom_boxplot()
ggplot(aes(x=Fashion, y=Engagment, color=PostType, shape=PostType), data=marketing_df) + geom_jitter(width=0.1) + facet_grid(.~SoicalMedia) + theme(axis.tetx.x=element_text(angle=90, vjust=0.5,hjust=1 ))
ggplot(aes(x=Fashion, y=Engagment, color=PostType, shape=PostType), data=marketing_df) + geom_jitter(width=0.1)
ggplot(aes(y=Engagement, x=Fashion, color=PostType), data=marketing_df) + geom_boxplot()
marketing_df$SoicalMedia <- as.factor(marketing_df$SoicalMedia)
str(marketing_df)
marketing_df$SocialMedia <- as.factor(marketing_df$SocialMedia)
ggplot(aes(x=Fashion, y=Engagment, color=PostType, shape=PostType), data=marketing_df) + geom_jitter(width=0.1) + facet_grid(.~SoicalMedia) + theme(axis.tetx.x=element_text(angle=90, vjust=0.5,hjust=1 ))
ggplot(aes(x=Fashion, y=Engagment, color=PostType, shape=PostType), data=marketing_df) + geom_jitter(width=0.1) + facet_grid(.~SocialMedia) + theme(axis.tetx.x=element_text(angle=90, vjust=0.5,hjust=1 ))
ggplot(aes(x=Fashion, y=Engagement, color=PostType, shape=PostType), data=marketing_df) + geom_jitter(width=0.1) + facet_grid(.~SocialMedia) + theme(axis.tetx.x=element_text(angle=90, vjust=0.5,hjust=1 ))
marketing_df.ml <- lmer(Engagement ~ Fashion + (1| SocialMedia) + (1|PostType), data=marketing_df)
summary(marketing_df.ml)
anova(marketing_df.ml)
fixef(marketing_df.ml)
ranef(marketing_df.ml)
fitness_df <- read.csv('fitness.csv')
str(fitness_df)
fitness_df$VO2max <- as.factor(fitness_df$VO2max)
ggplot(aes(y=VO2max, x=Week, group=Individual), data=fitness_df) + geom_point() + geom_line()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lmerTest)
library(Matrix)
library(lme4)
marketing_df <- read.csv('marketing.csv')
str(marketing_df)
marketing_df$SocialMedia <- as.factor(marketing_df$SocialMedia)
marketing_df$PostType <- as.factor(marketing_df$PostType)
marketing_df$Fashion <- as.factor(marketing_df$Fashion)
ggplot(aes(y=Engagement, x=Fashion, color=PostType), data=marketing_df) + geom_boxplot()
ggplot(aes(x=Fashion, y=Engagement, color=PostType, shape=PostType), data=marketing_df) + geom_jitter(width=0.1) + facet_grid(.~SocialMedia) + theme(axis.tetx.x=element_text(angle=90, vjust=0.5,hjust=1 ))
marketing_df.ml <- lmer(Engagement ~ Fashion + (1| SocialMedia) + (1|PostType), data=marketing_df)
anova(marketing_df.ml)
fixef(marketing_df.ml)
ranef(marketing_df.ml)
fitness_df <- read.csv('fitness.csv')
str(fitness_df)
fitness_df$Week <- as.factor(fitness_df$Week)
ggplot(aes(y=VO2max, x=Week, group=Individual), data=fitness_df) + geom_point() + geom_line()
fitness_df$Individual <- as.factor(fitness_df$Individual)
ggplot(aes(y=VO2max, x=Week, group=Individual), data=fitness_df) + geom_point() + geom_line()
library(readr)
population <- read_csv("C:/Users/Ethan/OneDrive/Cloud_Desktop/[00]UC/[01]2024_1/[01]STAT/[01]assignments/[98]Assignment 7/population.csv")
View(population)
library(readr)
power <- read_csv("C:/Users/Ethan/OneDrive/Cloud_Desktop/[00]UC/[01]2024_1/[01]STAT/[01]assignments/[98]Assignment 7/power.csv")
View(power)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lmerTest)
library(Matrix)
library(lme4)
power -> read.csv('power.csv')
power -> read.csv(power.csv)
power -> read.csv("power.csv")
str(power)
View(power)
str(power)
View(power)
print(View(power))
str(power)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lmerTest)
library(Matrix)
library(lme4)
View(power)
View(power)
par(mfrow = c(2, 4))  # Adjust the layout
boxplot(data$GlobalActivePower, main = "Global Active Power")
boxplot(data$GlobalReactivePower, main = "Global Reactive Power")
boxplot(data$Voltage, main = "Voltage")
boxplot(data$GlobalIntensity, main = "Global Intensity")
boxplot(data$Submetering1, main = "Submetering 1")
boxplot(data$Submetering2, main = "Submetering 2")
boxplot(data$Submetering3, main = "Submetering 3")
power -> read.csv("power.csv")
View(power)
boxplot(data$GlobalActivePower, main = "Global Active Power")
power -> read.csv('power.csv')
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lmerTest)
library(Matrix)
library(lme4)
power -> read.csv('power.csv')
power
power.t.test()
boxplot(data$GlobalActivePower, main = "GlobalActivePower")
power -> read.csv('power.csv')
library(lme4)
knitr::opts_chunk$set(echo = TRUE)
install.packages('tidyverse')
library(tidyverse)
install.packages("tidyverse")
library('tidyverse')
5+5
print('good')
{r}
install.packages('tinytex')
install.packages('tidyverse')
install.packages('tidyverse')
install.packages('tinytex')
5+5
library('tidyverse')
knitr::opts_chunk$set(echo = TRUE)
source("03_modeling.R")
lda_skills %>%
group_by(topic) %>%
top_n(10, beta) %>%
ggplot(aes(x = reorder(term, beta), y = beta, fill = as.factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
lda_responsibilites %>%
group_by(topic) %>%
top_n(10, beta) %>%
ggplot(aes(x = reorder(term, beta), y = beta, fill = as.factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
lda_field_studied %>%
group_by(topic) %>%
top_n(10, beta) %>%
ggplot(aes(x = reorder(term, beta), y = beta, fill = as.factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
lda_career %>%
group_by(topic) %>%
top_n(10, beta) %>%
ggplot(aes(x = reorder(term, beta), y = beta, fill = as.factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
lda_skills_required %>%
group_by(topic) %>%
top_n(10, beta) %>%
ggplot(aes(x = reorder(term, beta), y = beta, fill = as.factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
# Select unique company names and counts
sentiment_responsibilites
################################################################################
# Loading libraries
################################################################################
install.packages("patchwork")
knitr::opts_chunk$set(echo = TRUE)
#source("03_modeling.R")
plot_skills <- lda_skills %>%
group_by(topic) %>%
top_n(10, beta) %>%
ggplot(aes(x = reorder(term, beta), y = beta, fill = as.factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
ggtitle("Skills")
knitr::opts_chunk$set(echo = TRUE)
source("03_modeling.R")
plot_skills <- lda_skills %>%
group_by(topic) %>%
top_n(10, beta) %>%
ggplot(aes(x = reorder(term, beta), y = beta, fill = as.factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
ggtitle("Skills")
plot_skills_required <- lda_skills_required %>%
group_by(topic) %>%
top_n(10, beta) %>%
ggplot(aes(x = reorder(term, beta), y = beta, fill = as.factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
ggtitle("Skills Required")
plot_field_studied <- lda_field_studied %>%
group_by(topic) %>%
top_n(10, beta) %>%
ggplot(aes(x = reorder(term, beta), y = beta, fill = as.factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
ggtitle("Field Studied")
plot_career <- lda_career %>%
group_by(topic) %>%
top_n(10, beta) %>%
ggplot(aes(x = reorder(term, beta), y = beta, fill = as.factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
ggtitle("Career")
plot_responsibilites <- lda_responsibilites %>%
group_by(topic) %>%
top_n(10, beta) %>%
ggplot(aes(x = reorder(term, beta), y = beta, fill = as.factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
ggtitle("Responsibilities")
# Combine plots into a grid layout
combined_plot <- (plot_skills | plot_skills_required)
# Display the combined plot
combined_plot
sentiment_responsibilites
# Display the combined plot
View(combined_plot)
# Display the combined plot
combined_plot
knitr::opts_chunk$set(echo = TRUE)
source("04_ploting.R")
combined_plot
sentiment_responsibilites
language_counts
language_counts
edu_count
pro_comp_names
pro_comp_names <- resume_df %>%
count(professional_company_names, name = "Count") %>%
arrange(desc(Count[:-1]))
pro_comp_names <- resume_df %>%
count(professional_company_names, name = "Count") %>%
arrange(desc(Count[-1]))
setwd("C:/Users/Ethan/OneDrive/Cloud_Desktop/00_UC/00_2025_S2/00_LING/00_analysis/news_analysis")
# Sample sentences (replace with your actual sentences)
sentences <- c("I love to code", "Coding is fun", "R is great for data science")
# Step 1: Create and fit tokenizer
tokenizer <- text_tokenizer(oov_token = "<OOV>")
fit_text_tokenizer(tokenizer, sentences)
# Get word index
word_index <- tokenizer$word_index
# Step 2: Convert texts to sequences
sequences <- texts_to_sequences(tokenizer, sentences)
# Step 3: Pad sequences
padded <- pad_sequences(sequences, padding = "post")
# Output results
print("Word Index:")
print(word_index)
print("Sequences:")
print(sequences)
print("Padded Sequences:")
print(padded)
knitr::opts_chunk$set(echo = TRUE)
R.version.string
#use_virtualenv("C:/Users/Ethan/Documents/.virtualenvs/r-tensorflow", required = TRUE)
#is_keras_available()
#py_module_available("tensorflow")
# Loading
news_fake <- read.csv("C:\\Users\\Ethan\\OneDrive\\Cloud_Desktop\\00_UC\\00_2025_S2\\00_LING\\00_analysis\\data_sets\\fake.csv")
news_true <- read.csv("C:\\Users\\Ethan\\OneDrive\\Cloud_Desktop\\00_UC\\00_2025_S2\\00_LING\\00_analysis\\data_sets\\true.csv")
# Cleaning
news_true$text <- stringr::str_replace(news_true$text, "^.*?(?:\\(Reuters\\)\\s*-\\s*)", "")
news_true$text <- gsub("U.S.", "United States", news_true$text, fixed = TRUE)
news_true <- news_true[nchar(news_true$text) >= 25, ]
news_fake <- news_fake[nchar(news_fake$text) >= 25, ]
extract_first_sentence <- function(text) {
if (is.na(text) || text == "") {
return(NA_character_)
}
first_sentence <- str_extract(text, "^.*?[.!?](?=\\s|$)")
if (is.na(first_sentence)) {
return(trimws(text))
} else {
return(trimws(first_sentence))
}
}
# Building true news dataframe
one_sentence_true <- data.frame(
entry = 1:nrow(news_true),
first_sentence = sapply(news_true$text, extract_first_sentence),
truth_value = TRUE
)
rownames(one_sentence_true) <- NULL
one_sentence_true <- head(one_sentence_true, 500)
# Building fake news dataframe
one_sentence_fake <- data.frame(
entry = 1:nrow(news_fake),
first_sentence = sapply(news_fake$text, extract_first_sentence),
truth_value = FALSE
)
rownames(one_sentence_fake) <- NULL
one_sentence_fake <- head(one_sentence_fake, 500)
# Combining dataframes
if (!("index" %in% colnames(one_sentence_fake))) {
one_sentence_fake$index <- NULL
}
combined_df <- rbind(one_sentence_true, one_sentence_fake)
combined_df <- combined_df[nchar(combined_df$first_sentence) >= 50, ]
reindex_dataframe <- function(combined_df) {
# Assign new index based on row number
combined_df$index <- seq_len(nrow(combined_df))
return(df)
}
View(combined_df)
# Sample sentences (replace with your actual sentences)
sentences <- c("I love to code", "Coding is fun", "R is great for data science")
# Step 1: Create and fit tokenizer
tokenizer <- text_tokenizer(oov_token = "<OOV>")
fit_text_tokenizer(tokenizer, sentences)
# Get word index
word_index <- tokenizer$word_index
# Step 2: Convert texts to sequences
sequences <- texts_to_sequences(tokenizer, sentences)
# Step 3: Pad sequences
padded <- pad_sequences(sequences, padding = "post")
# Output results
print("Word Index:")
print(word_index)
print("Sequences:")
print(sequences)
print("Padded Sequences:")
print(padded)
R.version.string
is_keras_available()
py_module_available("tensorflow")
View(combined_df)
# Filter the dataframe to include only the specified entries
subset_df <- combined_df[combined_df$entry %in% entries, ]
# Assuming the dataframe is named 'df'
# Create a vector of the desired entry numbers
entries <- c(1:10, 501:510)
# Filter the dataframe to include only the specified entries
subset_df <- combined_df[combined_df$entry %in% entries, ]
View(subset_df)
write.csv(subset_df, "subset_dataframe.csv", row.names = FALSE)
View(subset_df)
install.packages("act")
library(act)
eaf_data <- ("C:\\Users\\Ethan\\OneDrive\\Cloud_Desktop\\00_UC\\00_2025_S2\\00_LING\\00_analysis\\data_sets\\\EG882_DeniseMcCulloch.eaf")
eaf_data <- import_eaf("C:\\Users\\Ethan\\OneDrive\\Cloud_Desktop\\00_UC\\00_2025_S2\\00_LING\\00_analysis\\data_sets\\\EG882_DeniseMcCulloch.eaf")
eaf_data <- read.csv("C:\\Users\\Ethan\\OneDrive\\Cloud_Desktop\\00_UC\\00_2025_S2\\00_LING\\00_analysis\\data_sets\\\EG882_DeniseMcCulloch.eaf")
eaf_data <- import_eaf("C:\\Users\\Ethan\\OneDrive\\Cloud_Desktop\\00_UC\\00_2025_S2\\00_LING\\00_analysis\\data_sets\\EG882_DeniseMcCulloch.eaf")
View(eaf_data)
str(eaf_data)
print(eaf_data)
eaf_data <- import_eaf("C:\\Users\\Ethan\\OneDrive\\Cloud_Desktop\\00_UC\\00_2025_S2\\00_LING\\00_analysis\\data_sets\\EG882_DeniseMcCulloch.eaf")
# Install and load xml2 package if not already installed
if (!require(xml2)) install.packages("xml2")
library(xml2)
# Read the .eaf file as an XML document
eaf_data <- read_xml(file_path)
# Read the .eaf file as an XML document
eaf_data <- read_xml(eaf_data)
eaf_data <- import_eaf("C:\\Users\\Ethan\\OneDrive\\Cloud_Desktop\\00_UC\\00_2025_S2\\00_LING\\00_analysis\\data_sets\\EG882_DeniseMcCulloch.eaf")
# Install and load xml2 package if not already installed
if (!require(xml2)) install.packages("xml2")
library(xml2)
# Find all tiers (adjust TIER_ID if you know the specific tier name, e.g., "transcription")
tiers <- xml_find_all(eaf_data, "//TIER")
file_path <- import_eaf("C:\\Users\\Ethan\\OneDrive\\Cloud_Desktop\\00_UC\\00_2025_S2\\00_LING\\00_analysis\\data_sets\\EG882_DeniseMcCulloch.eaf")
# Install and load xml2 package if not already installed
if (!require(xml2)) install.packages("xml2")
library(xml2)
# Read the .eaf file as an XML document
eaf_data <- read_xml(file_path)
file_path <- ("C:\\Users\\Ethan\\OneDrive\\Cloud_Desktop\\00_UC\\00_2025_S2\\00_LING\\00_analysis\\data_sets\\EG882_DeniseMcCulloch.eaf")
# Read the .eaf file as an XML document
eaf_data <- read_xml(file_path)
# Find all tiers (adjust TIER_ID if you know the specific tier name, e.g., "transcription")
tiers <- xml_find_all(eaf_data, "//TIER")
file_path <- ("C:\\Users\\Ethan\\OneDrive\\Cloud_Desktop\\00_UC\\00_2025_S2\\00_LING\\00_analysis\\data_sets\\EG882_DeniseMcCulloch.eaf")
# Read the .eaf file as an XML document
eaf_data <- read_xml(file_path)
# Find all tiers (adjust TIER_ID if you know the specific tier name, e.g., "transcription")
tiers <- xml_find_all(eaf_data, "//TIER")
# Initialize a data frame to store transcript data
transcript_data <- data.frame(
tier_id = character(),
annotation_id = character(),
time_start = character(),
time_end = character(),
transcript = character(),
stringsAsFactors = FALSE
)
# Loop through each tier to extract annotations
for (tier in tiers) {
# Get the tier ID (or name) for reference
tier_id <- xml_attr(tier, "TIER_ID")
# Find all annotations in this tier
annotations <- xml_find_all(tier, ".//ANNOTATION/ALIGNABLE_ANNOTATION")
# Extract annotation details
for (ann in annotations) {
ann_id <- xml_attr(ann, "ANNOTATION_ID")
time_slot_ref1 <- xml_attr(ann, "TIME_SLOT_REF1")
time_slot_ref2 <- xml_attr(ann, "TIME_SLOT_REF2")
transcript_text <- xml_text(xml_find_first(ann, ".//ANNOTATION_VALUE"))
# Get timestamps from TIME_SLOT elements
time_start <- xml_text(xml_find_first(eaf_data, sprintf("//TIME_SLOT[@TIME_SLOT_ID='%s']/@TIME_VALUE", time_slot_ref1)))
time_end <- xml_text(xml_find_first(eaf_data, sprintf("//TIME_SLOT[@TIME_SLOT_ID='%s']/@TIME_VALUE", time_slot_ref2)))
# Add to data frame
transcript_data <- rbind(transcript_data, data.frame(
tier_id = tier_id,
annotation_id = ann_id,
time_start = time_start,
time_end = time_end,
transcript = transcript_text,
stringsAsFactors = FALSE
))
}
}
# Print the transcript data
print(transcript_data)
# Optionally, save the transcript to a CSV file
write.csv(transcript_data, "eaf_transcript.csv", row.names = FALSE)
data <- read.csv(eaf_transcript.csv)
# Optionally, save the transcript to a CSV file
write.csv(transcript_data, "eaf_transcript.csv", row.names = FALSE)
data <- read.csv(eaf_transcript.csv)
